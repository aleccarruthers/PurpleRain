{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PurpleRain Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import PurpleRain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply import the PurpleRain library. Your .ipynb or .py file should be in the same file as PurpleRain.py.\n",
    "Many common libraries are already imported with PurpleRain. There's a chance a Python may throw a\n",
    "\"ModuleNotFoundError\" since so many libraries are used. Consult https://docs.anaconda.com/anaconda/user-guide/tasks/install-packages/ if you are using the Anaconda platform (includes Jupyter and Spyder) or https://docs.python.org/3/installing/index.html if you are using a different IDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PurpleRain import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use the pa_query function to access the Purple Air Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Variable Assignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the data structures used in the pa_query function are recycled in other PurpleRain functions. To simplify, first assign all to a concise yet informative variable then input into the function. The function requires:\n",
    "\n",
    "* sensor_list: A list of strings containing the ***exact*** names of the sensors as they appear on PA server. No need to include both A and B sensors.\n",
    "\n",
    "* driver_path: A string with the path to the chromedriver. **Be sure to enter the path to the csv file, if you don't replace 'insert_your_path_here' the code won't compile.**\n",
    "\n",
    "* start_date:  A date string of the form - 'MM/DD/YYYY'\n",
    "\n",
    "* end_date:    A date string of the form - 'MM/DD/YYYY' - must occur at *least* one day after the start date.\n",
    "\n",
    "* tz_str:      A string containing the timezone information. Visit https://en.wikipedia.org/wiki/List_of_tz_database_time_zones and look at the column titled 'TZ Database Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_list = ['UT Sensor 1','UT Sensor 4']\n",
    "driver_path = 'your_path_here'\n",
    "start_date  = '06/20/2019'\n",
    "end_date    = '08/18/2019'\n",
    "tz_str      = 'Asia/Calcutta'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. [Optional] The sensors_from_csv function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you may want to download a long list of sensors. It may be more practical for documentation purposes to simply process a csv file with the sensor list. The csvfile must have the sensor list in the first column with a header. Check the csv file for formatting best practices. **Be sure to enter the path to the csv file, if you don't replace 'insert_your_path_here' the code won't compile.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_list = sensors_from_csv('insert_your_path_here'+'sample_sensor_list.csv')\n",
    "print(sensor_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. pa_query implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, execute the function. You may notice the 0 before the previously assigned variables. 0 represents the query type. Currently only (1) query type is stable - \"Exact\" name, the fastest and most efficient query type. In future releases two additional query types will be supported: Lat-Lon bounds, and inexact sensor name queries. These two are **much slower** than type 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function requires an internet connection and properly assinged values for all the previously assigned variables. Please make sure you have followed all guidelines and check the documentation before reporting errors as bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_query(0, driver_path, sensor_list, start_date, end_date, tz_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow the function to run. Don't exit out of the webdriver. All files will appear in your Downloads file by default. Consult documentation for more information on the pa_query function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Organize files into a Hierarchical Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Variable Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only additional variables needed are the path to the downloads directory, and the name the our local PA database. For a name I have chosen \"Tutorial\" for the purposes of this file, but it can be called any string. Note that all .h5 files within in the same directory ***must*** have different names to avoid overwritting data. If you don't rename, you will raise an OSError. The downloads_path is the directory where the PA csvs have been downloaded in step 2c. If you have moved them from the default Downloads directory, use that directory instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5filename     = 'Tutorial'\n",
    "downloads_path = 'instert_downloads_path_here'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. The download_file_list function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the database, run the download_file_list function to build the list of files. The function returns the filenames for the next function, so be sure to assign a variable to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = downloaded_file_list(downloads_path, sensor_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. The build_hdf function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The build_hdf function will organize the csv files into one central platform, as well as calcualte 1-hr mean, median,\n",
    "standard deviation, and max values for each timestep for each parameter measured by the PAs. The .h5 file will be saved in the same directory as the this program or wherever you are running PurpleRain. build_hdf will return the \"keys\" or levels of the hdf file. It can be helpful for navigating the file, but it is not necessary to assign a variable to the function. Additionally, you can visualize the contents of the file with the NASA app Panoply: https://www.giss.nasa.gov/tools/panoply/download/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the HDF saves datetime in Julian date float format. Look here for more information: https://en.wikipedia.org/wiki/Julian_day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = build_hdf(names, h5filename, tz_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d. Convert hdf file to mat file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You maybe more comfortable with MATLAB. Although MATLAB has HDF support, it can be difficult to use and often rejects Python generated HDF files. Simply enter the name of the HDF file (assuming you have not moved it out of this directory, if you have put the directory in front of the filename string), and it will generate a mat file of the HDF in the same folder. Contact me if you are interested in MATLAB visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_to_mat(h5filename + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3e. Navigating the hdf file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To grab data arrays from the hdf file, you can use the syntax from the h5py library outlined here: http://docs.h5py.org/en/stable/high/dataset.html#reading-writing-data. Alternatively, you can use the function of this module called h5file_query. The function requires the h5 file name, and hierarchical query string. Sample usage is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default Panoply will fill any space with underscores, so the sensor named UT Sensor 1 will appear as UT_Sensor_1 in Panoply. The proper format for query is the sensor name with any spaces, and an additional space at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor='UT Sensor 1'\n",
    "\n",
    "A_PM25_1hr = h5file_query(h5filename+'.h5', sensor + ' /A/PM_CF/PM25/Subsampled/PM25_CF_Mean')\n",
    "B_PM25_1hr =  h5file_query(h5filename+'.h5', sensor + ' /A/PM_CF/PM25/Subsampled/PM25_CF_Mean')\n",
    "\n",
    "Data = pd.DataFrame([A,B])\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3f. [Optional] Import and Format Calibration Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibration data can come from many sources and therefore there is no uniform format. To use as a calibration source in this environment, convert to a time-indexed pandas dataframe with a single column representing the 1-hour averaged PM2.5 concentration. Consult https://pandas.pydata.org/pandas-docs/stable/index.html for more information. Below is an example of using data from a MetOne BAM-1022. **Be aware of your calibration data quality.** Many sensors will flag bad data but may not delete/nan it by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also keep in mind that example below is not necessarily the most efficient or strongest way of building the necessarry dataframe. Try experimenting with different arrangements to improve your Pandas skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAM_df = pd.read_csv('6_13_2019_to_8_19_2019_UT_BAM.csv')\n",
    "BAM_df = BAM_df.replace(99999, np.nan)\n",
    "Time = BAM_df.Time\n",
    "for i in range(0, len(Time)):\n",
    "    t = Time[i]\n",
    "    Time[i] = pd.Timestamp(t) - timedelta(hours=1) # BAM-1022 defines measurement hour different than pandas\n",
    "PM25 = BAM_df['ConcHR(ug/m3)']\n",
    "calibration_df = pd.DataFrame(PM25)\n",
    "calibration_df.index = Time\n",
    "calibration_df = calibration_df.resample('60T').apply(np.nanmean)\n",
    "calibration_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Some Visualizations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. PA Intra-sensor Comparison: a_vs_b_plot function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a_vs_b_plot generates a figure to understand the relationship between the A and B modules of the PA package. In theory they should have a perfectly 1:1 relationship. Input variables include the hdfile, the sensor name (one at a time for now), and whether to show the plot or not (irrelevant for Jupyter, but important for not overloading your screen with plots if using a different IDE or command line). The plots will be saved in this file with the sensor name as a png file. The function will also return the **slope**, **y-intercept**, **R**, **Pearson's r**, and **NRMSE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, b, R, r, nrmse = a_vs_b_plot(h5file, sensor, False)\n",
    "\n",
    "print('Slope: '+str(m))\n",
    "print('y-intercept: '+str(b))\n",
    "print('R2: '+str(R**2))\n",
    "print(\"Pearson's r: \"+str(r))\n",
    "print('NRMSE: '+str(nrmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. PA Calibration: calibration_plot function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have imported the calibration data, the calibration_plot can help you visualize the linear relationship betweeen the PA and the calibration instrument. Input variables include the hdfile, the sensor name (one at a time for now),the calibration pandas dataframe, and whether to show the plot or not (irrelevant for Jupyter, but important for not overloading your screen with plots if using a different IDE or command line). The plots will be saved in this file with the sensor name as a png file. The function will also return the **slope**, **y-intercept**, **R**, **Pearson's r**, and **NRMSE** for **both the A and B sensors**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_plot(h5file, sensor, calibration_df, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Scripting multiple sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this release, the plot functions can only handle one sensor at a time, however you can use the sensor name list and a for loop to run it for multiple sensors. Sample usage is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = []\n",
    "b = []\n",
    "R = []\n",
    "r = []\n",
    "nrmse = []\n",
    "\n",
    "for i in range(0, len(sensor_list)):\n",
    "    s = sensor_list[i]\n",
    "    output = a_vs_b_plot(h5file, s, False)\n",
    "    m = m + [output[0]]\n",
    "    b = b + [output[1]]\n",
    "    R = R + [output[2]]\n",
    "    r = r + [output[3]]\n",
    "    nrmse = nrmse + [output[4]]\n",
    "    \n",
    "print('Slope: ', m)\n",
    "print('y-intercept: ', b)\n",
    "print('R2: ', R**2)\n",
    "print(\"Pearson's r: \", r)\n",
    "print('NRMSE: ', nrmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. [Optional] Download Meteorological Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meteorological Data is vital to understanding low cost sensor data, especially Purple Airs. Relative Humidity, Temperature, Dew Point, Barometric Pressure, Wind Speed, Wind Direction, and Gust Speed all play a significant role in calibration and casual analysis of PM2.5 data. In future releases, functions will be added to include meteorological visualization and inclusion in calibration procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. Variable Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the downloader, you must specify the network, and weather station name. The network name is usally the name of the common name of the country (such as \"India\" or \"Democratic Republic of the Congo\"). If the station is in the US, the network is the name of the state (such as \"Iowa\" or \"New York\"). The station name usually corresponds to the airport name (such as \"JFK\" for JFK Airport, or \"AUS\" for Austin-Bergstorm Airport) or the met station name if not an airport (\"NYC\" for Central Park).\n",
    "Check the following for network and station names: https://mesonet.agron.iastate.edu/request/download.phtml. The start_date, and end_date, unlike the pa_query, use the datetime format of datetime(year, month, day) in integer casting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network     = 'India'\n",
    "station     = 'VOBG'\n",
    "start_date  = datetime(2019,6,20)\n",
    "end_date    = datetime(2019,8,19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Download Meteorological Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The download_met_data function is similar to the pa_query function in that it uses an automated webdriver to download data. It also requires the driver_path, along with the aforementioned network, station, start_date, and end_date. Remember not to exit the webdriver, it will automatically exit after the download is complete. The download file will have the same name as the station and will be a text file. It will automatically download to the default download directory. If there are multiple downloads from the same station it will begin namming in the format station+(integer).txt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_met_data(driver_path, network, station, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5c. Format Met Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The native text file contains bloat, and is in UTC timezone. format_met_data reformats the text file into a 1-hr averaged dataframe in the local timezone, and saves it as a csv file in the same folder as this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorology_df = format_met_data('insert_your_path_here'+station+.'txt', tz_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
